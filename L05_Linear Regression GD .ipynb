{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7846b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Note that linear regression and Adaline are very similar. The only difference is that we apply a threshold function for converting the outputs from continuous targets for predictions.\n",
    "###The derivative and training procedure are identical to Adaline though \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4481a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a27019",
   "metadata": {},
   "source": [
    "### Load & Prepare Toy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b2ae157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.942094</td>\n",
       "      <td>-0.835856</td>\n",
       "      <td>-22.324428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.222445</td>\n",
       "      <td>-0.403177</td>\n",
       "      <td>-52.121493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.112466</td>\n",
       "      <td>-1.688230</td>\n",
       "      <td>-57.043196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.403459</td>\n",
       "      <td>-0.412272</td>\n",
       "      <td>-27.701833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.021351</td>\n",
       "      <td>-0.499017</td>\n",
       "      <td>-9.804714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2          y\n",
       "995 -0.942094 -0.835856 -22.324428\n",
       "996  1.222445 -0.403177 -52.121493\n",
       "997 -0.112466 -1.688230 -57.043196\n",
       "998 -0.403459 -0.412272 -27.701833\n",
       "999  0.021351 -0.499017  -9.804714"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('linreg-data.csv' , index_col = 0)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36406feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Assign features and target \n",
    "X = torch.tensor(df[['x1' , 'x2']].values , dtype = torch.float)\n",
    "y = torch.tensor(df['y'].values , dtype = torch.float)\n",
    "\n",
    "\n",
    "##Shuffling & train/test split \n",
    "#set seed \n",
    "torch.manual_seed(123)\n",
    "#\n",
    "shuffle_idx = torch.randperm(y.size(0) , dtype = torch.long)\n",
    "\n",
    "X,y = X[shuffle_idx] , y[shuffle_idx] \n",
    "percent70 = int(shuffle_idx.size(0) * 0.7)\n",
    "\n",
    "X_train , X_test = X[shuffle_idx[ :percent70]] , X[shuffle_idx[percent70:]]\n",
    "y_train , y_test = y[shuffle_idx[:percent70]] , y[shuffle_idx[percent70:]]\n",
    "\n",
    "#Normalizing data \n",
    "mu,sigma = X_train.mean(dim = 0) , X_train.std(dim = 0)\n",
    "X_train = (X_train - mu)/sigma\n",
    "X_test = (X_test - mu)/sigma \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940e5d31",
   "metadata": {},
   "source": [
    "### Implementing Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147fe09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression1():\n",
    "    def __init__(self, num_features):\n",
    "        self.num_features = num_features\n",
    "        self.weights = torch.zeros(num_features, 1, \n",
    "                                   dtype=torch.float)\n",
    "        self.bias = torch.zeros(1, dtype=torch.float)\n",
    "\n",
    "    def forward(self, x):\n",
    "        netinputs = torch.add(torch.mm(x, self.weights), self.bias)\n",
    "        activations = netinputs\n",
    "        return activations.view(-1)\n",
    "        \n",
    "    def backward(self, x, yhat, y):  \n",
    "        \n",
    "        grad_loss_yhat = 2*(yhat - y)\n",
    "        \n",
    "        grad_yhat_weights = x\n",
    "        grad_yhat_bias = 1.\n",
    "        \n",
    "        # Chain rule: inner times outer\n",
    "        grad_loss_weights =  torch.mm(grad_yhat_weights.t(),\n",
    "                                         grad_loss_yhat.view(-1, 1)) / y.size(0)\n",
    "\n",
    "        grad_loss_bias = torch.sum(grad_yhat_bias*grad_loss_yhat) / y.size(0)\n",
    "        \n",
    "        # return negative gradient\n",
    "        return (-1)*grad_loss_weights, (-1)*grad_loss_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc8ce1e",
   "metadata": {},
   "source": [
    "### Defining training and evaluation functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "516ae8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "##Training and wrappers\n",
    "########################\n",
    "def loss(yhat,y):\n",
    "    return torch.mean((yhat -y) **2)\n",
    "\n",
    "def train( model , x , y , num_epochs, learning_rate = 0.01):\n",
    "    cost = []\n",
    "    for e in range(num_epochs):\n",
    "        \n",
    "        ##compute outputs \n",
    "        yhat = model.forward(x)\n",
    "        \n",
    "        ###compute gradients \n",
    "        negative_grad_w , negative_grad_b = model.backward(x , yhat , y)\n",
    "        \n",
    "        ###Updates weights \n",
    "        model.weights += learning_rate*negative_grad_w \n",
    "        model.bias += learning_rate*negative_grad_b\n",
    "        \n",
    "        ###logging \n",
    "        \n",
    "        yhat = model.forward(x)\n",
    "        curr_loss = loss(yhat , y)\n",
    "        print('Epoch: %03d' %(e+1) , end = '')\n",
    "        print(' | MSE: %.5f' % curr_loss)\n",
    "        cost.append(curr_loss)\n",
    "    return cost\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da944bb2",
   "metadata": {},
   "source": [
    "### Train Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27230f48",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LinearRegression1.__init__() missing 1 required positional argument: 'num_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLinearRegression1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m cost  \u001b[38;5;241m=\u001b[39m train(model , \n\u001b[0;32m      3\u001b[0m              X_train , y_train , \n\u001b[0;32m      4\u001b[0m              num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m , \n\u001b[0;32m      5\u001b[0m              learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: LinearRegression1.__init__() missing 1 required positional argument: 'num_features'"
     ]
    }
   ],
   "source": [
    "model = LinearRegression1()\n",
    "cost  = train(model , \n",
    "             X_train , y_train , \n",
    "             num_epochs = 100 , \n",
    "             learning_rate = 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5b68aff",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearRegression1' object has no attribute 'weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m test_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(X_test)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain MSE: \u001b[39m\u001b[38;5;132;01m%.5f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m loss(train_pred, y_train))\n",
      "Cell \u001b[1;32mIn[18], line 9\u001b[0m, in \u001b[0;36mLinearRegression1.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m ,x): \n\u001b[1;32m----> 9\u001b[0m     netinputs \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39madd(torch\u001b[38;5;241m.\u001b[39mmm(x,\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m) , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n\u001b[0;32m     10\u001b[0m     activations \u001b[38;5;241m=\u001b[39m netinputs \n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m activations\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LinearRegression1' object has no attribute 'weights'"
     ]
    }
   ],
   "source": [
    "train_pred = model.forward(X_train)\n",
    "test_pred = model.forward(X_test)\n",
    "\n",
    "print('Train MSE: %.5f' % loss(train_pred, y_train))\n",
    "print('Test MSE: %.5f' % loss(test_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a39e9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
